{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from src.serial import MatrixDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status\n",
    "UNKNOWN = -1\n",
    "NOISE = -2\n",
    "\n",
    "class DBSCAN(object):\n",
    "    \"\"\"\n",
    "    Base Class of DBSCAN, please do NOT instantiate this Class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        \"\"\"\n",
    "        DBSCAN Classes should be instantiate with data point set\n",
    "        \"\"\"\n",
    "        self.m, _ = (dataset, None)     # placeholder _ for future implementation of labels\n",
    "        self.num_p = self.m.shape[0]\n",
    "        self.tags = [UNKNOWN] * self.num_p\n",
    "\n",
    "    def _get_dist(self, a, b, fast_mode: bool = False) -> float:\n",
    "        \"\"\"\n",
    "        for float comparison, set all distance value precision to 5\n",
    "        :param: a: int; index of given point in data matrix\n",
    "        :param: b: same as a\n",
    "        :param: fast_mode: bool -> if True, ignore sqrt() opration for distance\n",
    "        \"\"\"\n",
    "        if fast_mode:\n",
    "            result = np.power(self.m[b] - self.m[a], 2).sum()\n",
    "        else:\n",
    "            result = np.sqrt(np.power(self.m[b] - self.m[a], 2).sum())\n",
    "        return round(result, 5)\n",
    "\n",
    "    def _get_neighbours(self, p: int, eps: float, fast_mode=False) -> list:\n",
    "        \"\"\"\n",
    "        return neighbours index of given point p in source data matrix\n",
    "        :param: p: int; index of given point in data matrix\n",
    "        :param: eps: float; the value of radius of density area\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _clustering(self, p, eps, min_pts, cluster_id, fast_mode=False):\n",
    "        \"\"\"\n",
    "        tag given point p and all of its neighbours and sub-neighbours with the same cluster id\n",
    "        :param: m: np.matrix; N * 2 matrix recoding all nodes' coordinates\n",
    "        :param: eps: float; the value of radius of density area\n",
    "        :param: min_pts: int; least neighbours should be in a density area\n",
    "        :param: cluster_id: int; current id of cluster\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _find_core_pts(self, eps, min_pts):\n",
    "        self.is_core = [0] * self.num_p\n",
    "        for i in range(self.num_p):\n",
    "            if len(self._get_neighbours(i, eps, min_pts)) > min_pts:\n",
    "                self.is_core[i] = 1\n",
    "        return self.is_core\n",
    "        \n",
    "\n",
    "    def predict(self, eps, min_pts, fast_mode=False) -> list:\n",
    "        \"\"\"\n",
    "        return list of labels as the sequence in data matrix\n",
    "        :param: m: np.matrix; N * 2 matrix recoding all nodes' coordinates\n",
    "        :param: eps: float; the value of radius of density area\n",
    "        :param: min_pts: int; least neighbours should be in a density area\n",
    "        \"\"\"\n",
    "        self.eps = eps\n",
    "        self.min_pts = min_pts\n",
    "\n",
    "        cluster_id = 1\n",
    "        for p_id in range(self.num_p):\n",
    "            if self.tags[p_id] != UNKNOWN:\n",
    "                continue\n",
    "            if self._clustering(p_id, eps, min_pts, cluster_id, fast_mode):\n",
    "                cluster_id += 1\n",
    "        return np.array(self.tags)\n",
    "\n",
    "\n",
    "class NaiveDBSCAN(DBSCAN):\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        super(NaiveDBSCAN, self).__init__(dataset)\n",
    "\n",
    "    def _get_neighbours(self, p: int, eps: float, fast_mode=False) -> list:\n",
    "\n",
    "        ngbs = []\n",
    "        for idx in range(len(self.m)):\n",
    "            if self._get_dist(p, idx, fast_mode) < eps:\n",
    "                ngbs.append(idx)\n",
    "        return ngbs\n",
    "\n",
    "    def _clustering(self, p, eps, min_pts, cluster_id, fast_mode=False) -> bool:\n",
    "\n",
    "        neighbours = self._get_neighbours(p, eps, fast_mode)\n",
    "        if len(neighbours) < min_pts:\n",
    "            self.tags[p] = NOISE\n",
    "            return False\n",
    "        else:\n",
    "            self.tags[p] = cluster_id\n",
    "            for idx in neighbours:\n",
    "                self.tags[idx] = cluster_id\n",
    "            while len(neighbours) > 0:\n",
    "                sub_neighbours = self._get_neighbours(neighbours[0], eps, fast_mode)\n",
    "                if len(sub_neighbours) >= min_pts:\n",
    "                    for sub_n in sub_neighbours:\n",
    "                        if self.tags[sub_n] < 0:\n",
    "                            self.tags[sub_n] = cluster_id\n",
    "                            if self.tags[sub_n] == UNKNOWN:\n",
    "                                neighbours.append(sub_n)\n",
    "                neighbours = neighbours[1:]\n",
    "        return True\n",
    "    \n",
    "\n",
    "class MatrixDBSCAN(DBSCAN):\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        super(MatrixDBSCAN, self).__init__(dataset)\n",
    "        self._get_distance_matrix()     # self.dist_m will be created\n",
    "        del self.m\n",
    "\n",
    "    def _get_distance_matrix(self):\n",
    "        \"\"\"\n",
    "        Only once calculation will be on each point-pairs\n",
    "        results will be stored in self.dist_m\n",
    "        \"\"\"\n",
    "\n",
    "        self.dist_m = np.zeros((self.num_p, self.num_p))\n",
    "        for p_id in range(self.num_p):\n",
    "            for q_id in range(p_id, self.num_p):\n",
    "                dist = self._get_dist(p_id, q_id)\n",
    "                self.dist_m[q_id, p_id] = dist\n",
    "                self.dist_m[p_id, q_id] = dist\n",
    "\n",
    "    def _get_neighbours(self, p: int, eps: float, fast_mode=False) -> list:\n",
    "        return np.nonzero(self.dist_m[p] < eps)[0]\n",
    "\n",
    "    def _clustering(self, p, eps, min_pts, cluster_id, fast_mode=False) -> bool:\n",
    "        \"\"\"\n",
    "        TODO: There should be some optimizations for this part, current code is too ugly\n",
    "        \"\"\"\n",
    "\n",
    "        neighbours = self._get_neighbours(p, eps, fast_mode)\n",
    "        if len(neighbours) < min_pts:\n",
    "            self.tags[p] = NOISE\n",
    "            return False\n",
    "        else:\n",
    "            self.tags[p] = cluster_id\n",
    "            for idx in neighbours:\n",
    "                self.tags[idx] = cluster_id\n",
    "            while len(neighbours) > 0:\n",
    "                sub_neighbours = self._get_neighbours(neighbours[0], eps, fast_mode)\n",
    "                if len(sub_neighbours) >= min_pts:\n",
    "                    for sub_n in sub_neighbours:\n",
    "                        if self.tags[sub_n] < 0:\n",
    "                            self.tags[sub_n] = cluster_id\n",
    "                            if self.tags[sub_n] == UNKNOWN:\n",
    "                                neighbours.append(sub_n)\n",
    "                neighbours = neighbours[1:]\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://leonlings-mbp:4046\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '../../data/shape-sets/r15_600.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_label(path):\n",
    "    pts = sc.textFile(path).map(lambda x: x.strip().split()[:-1]).map(lambda x: tuple([float(i) for i in x]))\n",
    "    return pts.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data_label(test_file)\n",
    "n_partitions = 4\n",
    "eps = 0.7\n",
    "min_pts = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(dataset, n_partitions, eps):\n",
    "    \n",
    "    # cut bins\n",
    "    lower_bound = np.min(dataset, axis=0)\n",
    "    upper_bound = np.max(dataset, axis=0)\n",
    "    a = np.linspace(lower_bound, upper_bound, n_partitions+1, endpoint=True)\n",
    "#     b = np.array([upper_bound])\n",
    "#     tmp_bin = np.concatenate((a, b), axis=0)\n",
    "    lower_bounds = [coordinates-eps for coordinates in a[:-1]]\n",
    "    upper_bounds = [coordinates+eps for coordinates in a[1:]]\n",
    "    print(lower_bounds)\n",
    "    print(upper_bounds)\n",
    "    \n",
    "    # scatter points into bins with eps\n",
    "    indexed_data = []\n",
    "    for id_pts in range(len(dataset)):     # index of point in dataset\n",
    "        for id_ptt in range(n_partitions):\n",
    "            if not (dataset[id_pts] > lower_bounds[id_ptt]).all():\n",
    "                continue\n",
    "            if not (dataset[id_pts] < upper_bounds[id_ptt]).all():\n",
    "                continue\n",
    "            indexed_data.append([id_ptt, id_pts])\n",
    "            \n",
    "    res = sc.parallelize(indexed_data).groupByKey().map(lambda x: [x[0], list(x[1])])\n",
    "    return res\n",
    "\n",
    "def local_dbscan(partioned_rdd):\n",
    "#     rdd_data = [data for data in partioned_rdd]\n",
    "#     ids = [id_pts for id_pts in rdd_data[0]]\n",
    "    dataset = np.array([b_dataset.value[idp] for idp in partioned_rdd])\n",
    "    dbscan_obj = MatrixDBSCAN(dataset)\n",
    "    dbscan_obj.predict(b_eps.value, b_min_pts.value)\n",
    "    is_core_list = dbscan_obj._find_core_pts(b_eps.value, b_min_pts.value)\n",
    "    \n",
    "    return list(zip(zip(partioned_rdd, is_core_list), dbscan_obj.tags))\n",
    "\n",
    "def merge(local_tags, dataset):\n",
    "    global_tags = [UNKNOWN] * len(dataset)\n",
    "    is_tagged = [0] * len(dataset)\n",
    "    last_max_label = 0\n",
    "    for local in local_tags:\n",
    "        np_local = np.array(local[-1])\n",
    "        np_local[:, -1] += last_max_label\n",
    "        last_max_label = np.max(np_local[:, -1])\n",
    "        \n",
    "        # check and merge overlapped points\n",
    "        tagged_indices = np.nonzero(is_tagged)[0]\n",
    "        for tmp_i in range(len(np_local)):\n",
    "            # should do tag check\n",
    "            (p_id, is_core), label = np_local[tmp_i]\n",
    "            if p_id in tagged_indices and is_core==1:\n",
    "                np_local[-1][np_local[-1]==label] = global_tags[p_id]\n",
    "        \n",
    "        # update global tags\n",
    "        for (p_id, is_core), label in np_local:\n",
    "            if is_tagged[p_id]==1:\n",
    "                continue\n",
    "            global_tags[p_id] = label\n",
    "            is_tagged[p_id] = 1\n",
    "    return global_tags\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2.702, 2.478]), array([6.1325, 5.9365]), array([9.563, 9.395]), array([12.9935, 12.8535])]\n",
      "[array([7.5325, 7.3365]), array([10.963, 10.795]), array([14.3935, 14.2535]), array([17.824, 17.712])]\n"
     ]
    }
   ],
   "source": [
    "b_dataset = sc.broadcast(dataset)\n",
    "b_eps = sc.broadcast(eps)\n",
    "b_min_pts = sc.broadcast(min_pts)\n",
    "\n",
    "partitioned_rdd = partition(dataset, n_partitions, eps)\n",
    "local_tags = partitioned_rdd.mapValues(lambda x: local_dbscan(x)).collect()\n",
    "result_tags = merge(local_tags, dataset)\n",
    "\n",
    "# partition(dataset, n_partitions, eps).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[array([2.702, 2.478]), array([6.1325, 5.9365]), array([9.563, 9.395]), array([12.9935, 12.8535])]\n",
    "[array([7.5325, 7.3365]), array([10.963, 10.795]), array([14.3935, 14.2535]), array([17.824, 17.712])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " -1,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " -1,\n",
       " -1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " -1,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " -1,\n",
       " 9,\n",
       " -1,\n",
       " -1,\n",
       " 9,\n",
       " 9,\n",
       " -1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " -1,\n",
       " 9,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 9,\n",
       " -1,\n",
       " 9,\n",
       " -1,\n",
       " -1,\n",
       " 9,\n",
       " 9,\n",
       " -1,\n",
       " 9,\n",
       " -1,\n",
       " 9,\n",
       " 9,\n",
       " -1,\n",
       " -1,\n",
       " 8,\n",
       " -1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 3,\n",
       " 3,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 3,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 3,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 3,\n",
       " -1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
