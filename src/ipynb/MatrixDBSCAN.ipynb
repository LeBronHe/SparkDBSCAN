{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Status\n",
    "UNKNOWN = -1\n",
    "NOISE = -2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBSCAN(object):\n",
    "    \"\"\"\n",
    "    Base Class of DBSCAN, please do NOT instantiate this Class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        DBSCAN Classes should be instantiate with data file path\n",
    "        \"\"\"\n",
    "        self.m, _ = self._load_data(path)\n",
    "        self.num_p = self.m.shape[0]\n",
    "        self.tags = [UNKNOWN] * self.num_p\n",
    "\n",
    "    def _load_data(self, path: str):\n",
    "        with open(path, 'r') as f:\n",
    "            data = []\n",
    "            label = []\n",
    "            for l in f.readlines():\n",
    "                source = l.strip().split()\n",
    "                data.append([float(val) for val in source[:2]])\n",
    "                label.append(int(source[-1]))\n",
    "            return np.array(data), np.array(label)\n",
    "        \n",
    "    def _get_dist(self, a, b, fast_mode: bool = False) -> float:\n",
    "        \"\"\"\n",
    "        for float comparison, set all distance value precision to 5\n",
    "        :param: a: int; index of given point in data matrix\n",
    "        :param: b: same as a\n",
    "        :param: fast_mode: bool -> if True, ignore sqrt() opration for distance\n",
    "        \"\"\"\n",
    "        if fast_mode:\n",
    "            result = np.power(self.m[b] - self.m[a], 2).sum()\n",
    "        else:\n",
    "            result = np.sqrt(np.power(self.m[b] - self.m[a], 2).sum())\n",
    "        return round(result, 5)\n",
    "    \n",
    "    def predict(self, eps, min_pts, fast_mode=False) -> list:\n",
    "        \"\"\"\n",
    "        return list of labels as the sequence in data matrix\n",
    "        :param: m: np.matrix; N * 2 matrix recoding all nodes' coordinates\n",
    "        :param: eps: float; the value of radius of density area\n",
    "        :param: min_pts: int; least neighbours should be in a density area\n",
    "        \"\"\"\n",
    "\n",
    "        cluster_id = 1\n",
    "        for p_id in range(self.num_p):\n",
    "            if self.tags[p_id] != UNKNOWN:\n",
    "                continue\n",
    "            if self._clustering(p_id, eps, min_pts, cluster_id, fast_mode):\n",
    "                cluster_id += 1\n",
    "        return np.array(self.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixDBSCAN(DBSCAN):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        super(MatrixDBSCAN, self).__init__(path)\n",
    "        self._get_distance_matrix()     # self.dist_m will be created\n",
    "#         del self.m\n",
    "\n",
    "    def _get_distance_matrix(self):\n",
    "        \"\"\"\n",
    "        Only once calculation will be on each point-pairs\n",
    "        results will be stored in self.dist_m\n",
    "        \"\"\"\n",
    "\n",
    "        self.dist_m = np.zeros((self.num_p, self.num_p))\n",
    "        for p_id in range(self.num_p):\n",
    "            for q_id in range(p_id, self.num_p):\n",
    "                dist = self._get_dist(p_id, q_id)\n",
    "                self.dist_m[q_id, p_id] = dist\n",
    "                self.dist_m[p_id, q_id] = dist\n",
    "\n",
    "    def _get_neighbours(self, p: int, eps: float, fast_mode=False) -> list:\n",
    "        return list(np.nonzero(self.dist_m[p] < eps))\n",
    "\n",
    "    def _clustering(self, p, eps, min_pts, cluster_id, fast_mode=False) -> bool:\n",
    "        \"\"\"\n",
    "        TODO: There should be some optimizations for this part, current code is too ugly\n",
    "        \"\"\"\n",
    "\n",
    "        neighbours = self._get_neighbours(p, eps, fast_mode)[0]\n",
    "        if len(neighbours) < min_pts:\n",
    "            self.tags[p] = NOISE\n",
    "            return False\n",
    "        else:\n",
    "            self.tags[p] = cluster_id\n",
    "            for idx in neighbours:\n",
    "                self.tags[idx] = cluster_id\n",
    "                \n",
    "            while len(neighbours) > 0:\n",
    "                sub_neighbours = self._get_neighbours(neighbours[0], eps, fast_mode)\n",
    "                if len(sub_neighbours) >= min_pts:\n",
    "                    for sub_n in sub_neighbours:\n",
    "                        if self.tags[sub_n] < 0:\n",
    "                            self.tags[sub_n] = cluster_id\n",
    "                            if self.tags[sub_n] == UNKNOWN:\n",
    "                                neighbours.append(sub_n)\n",
    "                neighbours = neighbours[1:]\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix DBSCAN:\n",
      "[ 1  2  2  2  3  3  3  4  4  4  5  5  5  6  6  6  7  7  7  8  8  8  9  9\n",
      "  9  9 10 10 10 10 11 11 11 11 12 12 12 12 13 13 13 13 14 14 14 14 15 15\n",
      " 15 15 15 16 16 16 16 16 17 17 17 17 17 18 18 18 18 18 19 19 19 19 19 19\n",
      " 20 20 20 20 20 20 21 21 21 21 21 21 21 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 22 22 22 22 22 22 22 23 24 24 24 25 25 25 26 26 26 27 27 27 28\n",
      " 28 28 29 29 29 30 30 30 30 31 31 31 31 32 32 32 32 33 33 33 33 34 34 34\n",
      " 34 35 35 35 35 36 36 36 36 37 37 37 37 37 38 38 38 38 38 39 39 39 39 39\n",
      " 40 40 40 40 40 40 41 41 41 41 41 41 42 42 42 42 42 42 42 43 43 43 43 43\n",
      " 43 43 44 44 44 44 44 44 44 44 44 44 44 44 44 45 46 46 46 47 47 47 48 48\n",
      " 48 49 49 49 50 50 50 51 51 51 52 52 52 53 53 53 53 54 54 54 54 55 55 55\n",
      " 55 56 56 56 56 57 57 57 57 58 58 58 58 59 59 59 59 59 60 60 60 60 60 61\n",
      " 61 61 61 61 62 62 62 62 62 62 63 63 63 63 63 63 64 64 64 64 64 64 64 65\n",
      " 65 65 65 65 65 65 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66]\n",
      "parallal run time: 0.5826399326324463\n"
     ]
    }
   ],
   "source": [
    "#### serial #####\n",
    "\n",
    "src = 'spiral.txt'\n",
    "\n",
    "print('Matrix DBSCAN:')\n",
    "start_time = time.time()\n",
    "mdbscan = MatrixDBSCAN(src)\n",
    "end_time = time.time()\n",
    "print(mdbscan.predict(2.5, 3))\n",
    "print('parallal run time:', end_time - start_time)\n",
    "del mdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixDBSCAN_parallel(object):\n",
    "\n",
    "    def __init__(self, path, iterator):\n",
    "\n",
    "        self.m, self.indices = self._load_data(path, iterator)\n",
    "        self.num_p = self.m.shape[0]\n",
    "        self.tags = [UNKNOWN] * self.num_p\n",
    "        self._get_distance_matrix()     \n",
    "\n",
    "    def _load_data(self, path: str, iterator):\n",
    "        indices = []\n",
    "        for i in iterator:\n",
    "            indices.append(i)\n",
    "            \n",
    "        with open(path, 'r') as f:\n",
    "            data = []\n",
    "            count = 0\n",
    "            for l in f.readlines():\n",
    "                if count not in indices:\n",
    "                    count += 1\n",
    "                    continue\n",
    "                source = l.strip().split()\n",
    "                data.append([float(val) for val in source[:2]])\n",
    "                count += 1\n",
    "        \n",
    "        return np.array(data), indices\n",
    "    \n",
    "    def _get_distance_matrix(self):\n",
    "\n",
    "        self.dist_m = np.zeros((self.num_p, self.num_p))\n",
    "        for p_id in range(self.num_p):\n",
    "            for q_id in range(p_id, self.num_p):\n",
    "                dist = self._get_dist(p_id, q_id)\n",
    "                self.dist_m[q_id, p_id] = dist\n",
    "                self.dist_m[p_id, q_id] = dist\n",
    "                \n",
    "    def _get_dist(self, a, b, fast_mode: bool = False) -> float:\n",
    "\n",
    "        if fast_mode:\n",
    "            result = np.power(self.m[b] - self.m[a], 2).sum()\n",
    "        else:\n",
    "            result = np.sqrt(np.power(self.m[b] - self.m[a], 2).sum())\n",
    "        return round(result, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_f(iterator):\n",
    "    \n",
    "    instance = MatrixDBSCAN_parallel(src, iterator)\n",
    "    \n",
    "    print(predict(instance, 2.5, 3))  \n",
    "\n",
    "    return list(zip(instance.indices, instance.tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result():\n",
    "    predictions = [UNKNOWN] * basic.num_p\n",
    "    base = 0\n",
    "    for local_result in local_results:\n",
    "\n",
    "        tuples = sorted(local_result[1])\n",
    "\n",
    "    #     print('tuples',tuples)\n",
    "\n",
    "        combined_c = {}\n",
    "\n",
    "        for local_pred in tuples:\n",
    "            if predictions[local_pred[0]] != UNKNOWN:\n",
    "                old_c = predictions[local_pred[0]]\n",
    "                combined_c[local_pred[1]] = old_c\n",
    "                ## 如果有两点在此区中分为一个cluster，但曾被分为不同cluster，则这两点会被更新为同一个cluster,这个cluster是靠后的点的old_cluster\n",
    "\n",
    "    #     print('combined_c',combined_c)\n",
    "\n",
    "\n",
    "        new_tuples = []\n",
    "        next_c = 1\n",
    "        flag = 0\n",
    "\n",
    "        for local_pred in tuples:\n",
    "            if local_pred[1] in combined_c.keys():\n",
    "                print('combined ', local_pred)\n",
    "                new_tuples.append((local_pred[0], combined_c[local_pred[1]]))\n",
    "            else:\n",
    "\n",
    "                new_c = local_pred[1]\n",
    "\n",
    "                if flag == 0:\n",
    "                    if new_c >= next_c:\n",
    "                        new_tuples.append((local_pred[0], next_c))\n",
    "                    else:\n",
    "                        print('error')\n",
    "                else:\n",
    "                    if last_c  == new_c:\n",
    "                        new_tuples.append((local_pred[0], next_c))\n",
    "                    elif new_c >= last_c + 1:\n",
    "                        next_c += 1\n",
    "                        new_tuples.append((local_pred[0], next_c))\n",
    "                    else:\n",
    "                        print('error')\n",
    "\n",
    "                last_c = new_c\n",
    "\n",
    "                if flag == 0:\n",
    "                    flag = 1\n",
    "\n",
    "\n",
    "    #     print('new_tuples',new_tuples)\n",
    "\n",
    "        max_c_num = 0\n",
    "\n",
    "        for local_pred in new_tuples:\n",
    "            local_c = local_pred[1]\n",
    "            if predictions[local_pred[0]] == UNKNOWN:\n",
    "                predictions[local_pred[0]] = local_c + base\n",
    "                if local_c > max_c_num:\n",
    "                    max_c_num = local_c\n",
    "\n",
    "\n",
    "        base = max_c_num\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix DBSCAN:\n",
      "[20, 21, 21, 21, 22, 22, 22, 23, 23, 23, 24, 24, 24, 18, 19, 19, 19, 20, 20, 20, 20, 7, 8, 8, 8, 8, 9, 9, 9, 9, 10, 10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 21, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 25, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 24, 24, 24, 25, 25, 25, 28, 29, 29, 29, 30, 30, 30, 31, 31, 31, 32, 32, 32, 33, 33, 33, 34, 34, 34, 34, 35, 35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 26, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 16, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 6, 21, 22, 22, 22, 23, 23, 23, 23, 23, 23, 31, 32, 32, 32, 32, 33, 33, 33, 33, 33, 40, 41, 41, 41, 41, 42, 42, 42, 42, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47, 34, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36]\n",
      "parallal run time: 0.2084670066833496\n"
     ]
    }
   ],
   "source": [
    "print('Matrix DBSCAN:')\n",
    "basic = MatrixDBSCAN(src)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "low = np.min(basic.m, axis=0)[0]\n",
    "upper = np.max(basic.m, axis=0)[0]\n",
    "\n",
    "n_partitions = 4\n",
    "\n",
    "bins = np.linspace(low, upper, num=n_partitions, endpoint=False)\n",
    "\n",
    "edges = np.array(range(basic.num_p))\n",
    "\n",
    "edge_partitions = []\n",
    "\n",
    "for e in edges: \n",
    "#     print(test.m[e])\n",
    "    for i in range(n_partitions-1, -1, -1):\n",
    "#         print(test.m[e][0], bins[i])\n",
    "        if test.m[e][0]>=bins[i]-min_pts:\n",
    "            edge_partitions.append((i, e))\n",
    "            break\n",
    "\n",
    "local_results = sc.parallelize(edge_partitions).groupByKey().mapValues(lambda xs: test_f(xs)).collect()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(get_result())\n",
    "\n",
    "print('parallal run time:', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del basic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
